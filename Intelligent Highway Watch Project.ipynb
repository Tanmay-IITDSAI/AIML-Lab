{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IHWP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Members:\n",
    "Vedansh Sharma (12242000) \\\n",
    "Tanmay Kumar Shrivastava \\\n",
    "Deepak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-An Adaptive and Reliable Digital Image Processing Method for Detecting Stop Lines and Correlating Colors to Traffic Light States at Night\n",
    "\n",
    "-Efficient Extraction of License Plates from Night-Time Traffic Images Using Digital Image Processing Techniques\n",
    "\n",
    "-License Plate Text Recognition Utilizing PyTesseract OCR\n",
    "\n",
    "-Dynamic Display of Penalized License Plates on Video Frames\n",
    "\n",
    "-MySQL Database Integration for Logging License Plate Violations with Fines (In the final phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import pytesseract\n",
    "import easyocr\n",
    "import re\n",
    "import mysql.connector\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from collections import deque\n",
    "from mysql.connector import Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a video from https://www.videvo.net/video/cars-trucksbus-and-taxis-on-the-highway-in-victoria-city/1619206/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light Colour recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this segment, our goal is to identify the color of a traffic light in real-time from a given frame. We took the following steps:\n",
    "\n",
    "1. Region of Interest: We start by defining a specific area within the image where we expect to find the traffic light. This isolates the relevant portion from the rest of the image, allowing us to focus our analysis.\n",
    "\n",
    "2. HSV Conversion: The ROI is converted from the RGB color space to HSV (Hue, Saturation, Value). The HSV color model is often preferred for color detection tasks, as it separates chromatic information (hue) from luminance.\n",
    "\n",
    "3. Defining Color Ranges: We establish the range of hue values that correspond to red and yellow colors. These defined ranges are critical for determining whether the traffic light is showing red, yellow, or green.\n",
    "\n",
    "4. Creating Color Masks: Using the defined color ranges, we generate masks (binary images) that highlight areas within the ROI where red and yellow colors are detected.\n",
    "\n",
    "5. Color Detection: We then analyze the masks. If any non-zero values appear in the red mask, we interpret this as the light being red. If the yellow mask contains non-zero values, we identify the light as yellow. If neither red nor yellow is present, we conclude that the light is green.\n",
    "\n",
    "6. Overlaying Status Information: Finally, we overlay a message on the main image indicating the detected status of the traffic light. This provides a visual cue indicating whether the signal is \"Stop,\" \"Caution,\" or \"Go.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_traffic_light_color(frame, bounding_box):\n",
    "    # Unpack the bounding box dimensions\n",
    "    x_coord, y_coord, width, height = bounding_box\n",
    "    # Isolate the region of interest (ROI) from the frame\n",
    "    region_of_interest = frame[y_coord:y_coord+height, x_coord:x_coord+width]\n",
    "    \n",
    "    # Convert the ROI from BGR to HSV color space\n",
    "    hsv_image = cv2.cvtColor(region_of_interest, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Set the HSV color range for red traffic lights\n",
    "    lower_red = np.array([0, 120, 70])\n",
    "    upper_red = np.array([10, 255, 255])\n",
    "    \n",
    "    # Set the HSV color range for yellow traffic lights\n",
    "    lower_yellow = np.array([20, 100, 100])\n",
    "    upper_yellow = np.array([30, 255, 255])\n",
    "\n",
    "    # Generate binary masks to identify red and yellow colors in the ROI\n",
    "    mask_red = cv2.inRange(hsv_image, lower_red, upper_red)\n",
    "    mask_yellow = cv2.inRange(hsv_image, lower_yellow, upper_yellow)\n",
    "    \n",
    "    # Define text font properties for overlaying information on the frame\n",
    "    text_font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "    text_scale = 1  \n",
    "    text_thickness = 2  \n",
    "    \n",
    "    # Determine which color is detected based on the masks\n",
    "    if cv2.countNonZero(mask_red) > 0:\n",
    "        display_color = (0, 0, 255)  # Red color for text\n",
    "        status_message = \"Detected Signal Status: Stop\"\n",
    "        detected_color = 'red'\n",
    "    elif cv2.countNonZero(mask_yellow) > 0:\n",
    "        display_color = (0, 255, 255)  # Yellow color for text\n",
    "        status_message = \"Detected Signal Status: Caution\"\n",
    "        detected_color = 'yellow'\n",
    "    else:\n",
    "        display_color = (0, 255, 0)  # Green color for text\n",
    "        status_message = \"Detected Signal Status: Go\"\n",
    "        detected_color = 'green'\n",
    "        \n",
    "    # Overlay the identified traffic light status onto the main frame\n",
    "    cv2.putText(frame, status_message, (15, 70), text_font, text_scale + 0.5, display_color, text_thickness + 1, cv2.LINE_AA)\n",
    "    # Draw a separator line\n",
    "    cv2.putText(frame, '-' * 34, (10, 115), text_font, text_scale, (255, 255, 255), text_thickness, cv2.LINE_AA)\n",
    "    \n",
    "    # Return the updated frame and the identified traffic light color\n",
    "    return frame, detected_color\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop line detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LineDetector class is designed to detect and highlight stop lines in video frames, adapting the visualization based on traffic light colors.\n",
    "\n",
    "Key Features:\n",
    "-Initialization: The class uses two queues (y_start_queue and y_end_queue) to store the y-coordinates of the stop line across frames. This helps smooth out fluctuations and provides a consistent representation of the line.\n",
    "\n",
    "-Color Mapping: A helper function, get_color_code, maps traffic light colors to their BGR equivalents. This allows the detected stop line to be highlighted according to the traffic light status.\n",
    "\n",
    "-Line Equations: Using given slope and intercept values, the class generates three equations to identify the relevant line segment.\n",
    "\n",
    "-Creating Masks: Masks are created based on the line equations to focus on the area of interest, reducing distractions from the background.\n",
    "\n",
    "-Image Processing: The masks are transformed through grayscale conversion, blurring, histogram equalization, and edge detection.\n",
    "\n",
    "-Hough Line Transform: The Hough Line Transform is applied to detect the stop line based on the processed edges, and the line parameters are stored in the queues.\n",
    "\n",
    "-Line Drawing & Coloring: The detected line is drawn on the original frame, colored according to the traffic light status by adjusting the frame's color channels.\n",
    "\n",
    "-Final Mask Creation: A final mask is produced to turn pixels above the detected line black. This mask is essential for isolating vehicles that have crossed the stop line when the light is red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "\n",
    "class LineDetector:\n",
    "    def __init__(self, frame_count_avg=10):\n",
    "        # Initialize deques to keep track of y-coordinates for line positions\n",
    "        self.start_y_queue = deque(maxlen=frame_count_avg)\n",
    "        self.end_y_queue = deque(maxlen=frame_count_avg)\n",
    "\n",
    "    def detect_white_line(self, image, traffic_light_color, \n",
    "                         slope1=0.03, intercept1=920, slope2=0.03, intercept2=770, slope3=-0.8, intercept3=2420):\n",
    "\n",
    "        # Map traffic light colors to BGR format\n",
    "        def color_mapping(color_name):\n",
    "            color_dict = {\n",
    "                'red': (0, 0, 255),\n",
    "                'green': (0, 255, 0),\n",
    "                'yellow': (0, 255, 255)\n",
    "            }\n",
    "            return color_dict.get(color_name.lower())\n",
    "\n",
    "        original_frame = image.copy()\n",
    "\n",
    "        # Define line equations for the areas of interest\n",
    "        def first_line(x): return slope1 * x + intercept1\n",
    "        def second_line(x): return slope2 * x + intercept2\n",
    "        def third_line(x): return slope3 * x + intercept3\n",
    "\n",
    "        height, width, _ = image.shape\n",
    "        \n",
    "        # Create a mask to highlight the area around the stop line\n",
    "        mask_area1 = image.copy()\n",
    "        for x in range(width):\n",
    "            y_value = first_line(x)\n",
    "            mask_area1[int(y_value):, x] = 0\n",
    "\n",
    "        mask_area2 = mask_area1.copy()\n",
    "        for x in range(width):\n",
    "            y_value = second_line(x)\n",
    "            mask_area2[:int(y_value), x] = 0\n",
    "\n",
    "        final_mask = mask_area2.copy()\n",
    "        for y in range(height):\n",
    "            x_value = third_line(y)\n",
    "            final_mask[y, :int(x_value)] = 0\n",
    "\n",
    "        # Convert the mask to grayscale and apply filters\n",
    "        gray_mask = cv2.cvtColor(final_mask, cv2.COLOR_BGR2GRAY)\n",
    "        blurred_mask = cv2.GaussianBlur(gray_mask, (7, 7), 0)\n",
    "\n",
    "        # Use CLAHE to enhance the image\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        enhanced_mask = clahe.apply(blurred_mask)\n",
    "\n",
    "        # Perform edge detection\n",
    "        detected_edges = cv2.Canny(gray_mask, 30, 100)\n",
    "\n",
    "        # Close gaps in edges using dilation and erosion\n",
    "        dilated_edges = cv2.dilate(detected_edges, None, iterations=1)\n",
    "        cleaned_edges = cv2.erode(dilated_edges, None, iterations=1)\n",
    "\n",
    "        # Detect lines using Hough Transform\n",
    "        detected_lines = cv2.HoughLinesP(cleaned_edges, 1, np.pi/180, 100, minLineLength=160, maxLineGap=5)\n",
    "\n",
    "        # Initialize x-coordinates for line start and end\n",
    "        x_start = 0\n",
    "        x_end = width - 1\n",
    "\n",
    "        if detected_lines is not None:\n",
    "            for line in detected_lines:\n",
    "                x1, y1, x2, y2 = line[0]\n",
    "\n",
    "                # Calculate line slope and intercept\n",
    "                line_slope = (y2 - y1) / (x2 - x1 + np.finfo(float).eps)  # Avoid division by zero\n",
    "                line_intercept = y1 - line_slope * x1\n",
    "\n",
    "                # Determine y-coordinates based on the line equations\n",
    "                y_start = int(line_slope * x_start + line_intercept)\n",
    "                y_end = int(line_slope * x_end + line_intercept)\n",
    "\n",
    "                # Store y-coordinates in queues for averaging\n",
    "                self.start_y_queue.append(y_start)\n",
    "                self.end_y_queue.append(y_end)\n",
    "\n",
    "        # Compute average y-coordinates for the stop line\n",
    "        avg_y_start = int(sum(self.start_y_queue) / len(self.start_y_queue)) if self.start_y_queue else 0\n",
    "        avg_y_end = int(sum(self.end_y_queue) / len(self.end_y_queue)) if self.end_y_queue else 0\n",
    "\n",
    "        # Adjust line position for drawing\n",
    "        line_start_offset = 0.32\n",
    "        adjusted_x_start = x_start + int(line_start_offset * (x_end - x_start))\n",
    "        adjusted_y_start = avg_y_start + int(line_start_offset * (avg_y_end - avg_y_start))\n",
    "\n",
    "        # Create a mask for drawing the detected line\n",
    "        draw_mask = np.zeros_like(image)\n",
    "\n",
    "        # Draw the stop line on the mask\n",
    "        cv2.line(draw_mask, (adjusted_x_start, adjusted_y_start), (x_end, avg_y_end), (255, 255, 255), 4)\n",
    "\n",
    "        # Determine which color channels to modify based on the traffic light color\n",
    "        color_code = color_mapping(traffic_light_color)\n",
    "        if color_code == (0, 255, 0):  # Green\n",
    "            channel_indices = [1]\n",
    "        elif color_code == (0, 0, 255):  # Red\n",
    "            channel_indices = [2]\n",
    "        elif color_code == (0, 255, 255):  # Yellow\n",
    "            channel_indices = [1, 2]  # Modify both green and red channels\n",
    "        else:\n",
    "            raise ValueError('Unsupported color')\n",
    "\n",
    "        # Change the specified color channels in the original frame where the mask is white\n",
    "        for channel_index in channel_indices:\n",
    "            image[draw_mask[:,:,channel_index] == 255, channel_index] = 255\n",
    "\n",
    "        # Calculate average slope and intercept for the stop line\n",
    "        avg_slope = (avg_y_end - avg_y_start) / (x_end - x_start + np.finfo(float).eps)\n",
    "        avg_intercept = avg_y_start - avg_slope * x_start\n",
    "\n",
    "        # Create a mask to highlight the area above the stop line\n",
    "        above_line_mask = np.copy(original_frame)\n",
    "        for x in range(width):\n",
    "            y_value = avg_slope * x + avg_intercept - 35\n",
    "            above_line_mask[:int(y_value), x] = 0  # Set pixels above the line to black\n",
    "\n",
    "        return image, above_line_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License Plate Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing: We start by converting the image to grayscale to work with single-channel intensity values. It applies Contrast Limited Adaptive Histogram Equalization (CLAHE) to enhance the image contrast by equalizing the histogram. To reduce noise and prepare for more precise detection, erosion is also performed.\n",
    "\n",
    "Isolating and Cropping the Region of Interest (ROI): Utilizing a mask from earlier steps, where pixels above the stop line are rendered black, the code identifies the non-black pixels that indicate the road area beneath the stop line. A bounding box is calculated around this region, and a portion on the left side, belonging to the opposite lane, is excluded. This refined cropped region becomes the primary ROI for detecting license plates, as the Haar cascade classifier operates more effectively on smaller, well-defined areas.\n",
    "\n",
    "Haar Cascade Classifier: The cropped grayscale image is then processed using a Haar cascade classifier, a traditional non-deep learning approach proficient in pattern recognition. This classifier has been pre-trained to identify license plate patterns, returning the locations of possible license plates as rectangles.\n",
    "\n",
    "Extracting License Plates & Final Output: The function marks the detected license plates on the original frame with rectangles. Additionally, the potential license plates are cropped from the grayscale image and stored in a list. The function concludes by returning the original frame with the bounded license plates and the list of detected license plates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_license_plate(frame, mask_line):\n",
    "    # Convert the frame to grayscale, as Haar cascades typically operate on single-channel images\n",
    "    gray_image = cv2.cvtColor(mask_line, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Utilize CLAHE for histogram equalization to enhance image contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_gray = clahe.apply(gray_image)\n",
    "    \n",
    "    # Apply erosion with a 2x2 kernel to minimize noise in the image\n",
    "    erosion_kernel = np.ones((2, 2), np.uint8)\n",
    "    processed_gray = cv2.erode(enhanced_gray, erosion_kernel, iterations=1)\n",
    "\n",
    "    # Identify the bounding box around non-black pixels\n",
    "    non_black_area = cv2.findNonZero(processed_gray)\n",
    "    x, y, width, height = cv2.boundingRect(non_black_area)\n",
    "\n",
    "    # Adjust the width of the bounding box by excluding 30% from the right side\n",
    "    adjusted_width = int(width * 0.7)\n",
    "\n",
    "    # Crop the grayscale image to the identified bounding box\n",
    "    cropped_gray_image = processed_gray[y:y + height, x:x + adjusted_width]\n",
    "\n",
    "    # Use the Haar cascade classifier to detect license plates in the cropped image\n",
    "    detected_license_plates = license_plate_cascade.detectMultiScale(cropped_gray_image, scaleFactor=1.07, minNeighbors=15, minSize=(20, 20))\n",
    "\n",
    "    # Initialize a list to store cropped license plate images\n",
    "    extracted_license_plate_images = []\n",
    "\n",
    "    # Iterate over detected license plates\n",
    "    for (plate_x, plate_y, plate_width, plate_height) in detected_license_plates:\n",
    "        # Draw rectangles around the detected license plates in the original frame\n",
    "        cv2.rectangle(frame, (plate_x + x, plate_y + y), (plate_x + x + plate_width, plate_y + y + plate_height), (0, 255, 0), 3)\n",
    "        \n",
    "        # Crop the detected license plate from the grayscale image and add it to the list\n",
    "        license_plate_crop = cropped_gray_image[plate_y:plate_y + plate_height, plate_x:plate_x + plate_width]\n",
    "        extracted_license_plate_images.append(license_plate_crop)\n",
    "\n",
    "    return frame, extracted_license_plate_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognising text on License plates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The apply_ocr_to_image function is designed to recognize and extract text, such as numbers and letters, from license plate images using PyTesseract OCR. It has the following steps:\n",
    "\n",
    "Image Thresholding: The function converts the image into a black-and-white format. This helps to separate the text from the background, making the text on the license plate black and the background white.\n",
    "\n",
    "Format Conversion: Since PyTesseract needs images in the PIL Image format, the function converts the thresholded image (which is in OpenCV format) into a format that PyTesseract can use.\n",
    "\n",
    "Text Extraction: The function uses PyTesseract to pull out text from the converted image. It uses a special setting (--psm 6) to help the OCR recognize text that is spread out, which is common for license plates.\n",
    "\n",
    "Text Cleanup: After extracting the text, the function removes any extra spaces at the beginning or end of the recognized text, ensuring that the result is clean and neat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ocr_to_image(license_plate_image):    \n",
    "    # Apply thresholding to convert the image to binary\n",
    "    _, binary_image = cv2.threshold(license_plate_image, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Convert the binary image from OpenCV format to PIL format\n",
    "    pil_image = Image.fromarray(binary_image)\n",
    "\n",
    "    # Extract text from the image using PyTesseract with a specified configuration\n",
    "    extracted_text = pytesseract.image_to_string(pil_image, config='--psm 6')\n",
    "\n",
    "    # Return the extracted text with leading and trailing whitespace removed\n",
    "    return extracted_text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying Penalised License Plates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The draw_penalized_text function is designed to display penalized license plates on video frames. This dynamic feature ensures that each fined license plate appears in the order it was identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_penalized_license_plates(frame):\n",
    "    # Define the font style, scale, thickness, and color\n",
    "    font_style = cv2.FONT_HERSHEY_TRIPLEX\n",
    "    scale = 1  \n",
    "    thickness = 2\n",
    "    text_color = (255, 255, 255)  # White\n",
    "\n",
    "    # Starting Y-coordinate for text placement\n",
    "    y_coordinate = 180\n",
    "    \n",
    "    # Draw the title on the frame\n",
    "    cv2.putText(frame, 'Fined License Plates:', (25, y_coordinate), font_style, scale, text_color, thickness)\n",
    "    \n",
    "    # Increment the Y-coordinate for the next line\n",
    "    y_coordinate += 80\n",
    "\n",
    "    # Iterate through the list of penalized license plates\n",
    "    for license_plate in penalized_texts:\n",
    "        # Display each penalized license plate on the frame\n",
    "        cv2.putText(frame, '->  ' + license_plate, (40, y_coordinate), font_style, scale, text_color, thickness)\n",
    "        \n",
    "        # Update the Y-coordinate for the next license plate entry\n",
    "        y_coordinate += 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Processing Video Feed\n",
    "\n",
    "-Traffic Light Detection: The color of the traffic light in the current frame is determined using the detect_traffic_light_color function.\n",
    "\n",
    "-Stop Line Detection: The function utilizes the LineDetector class to locate the white stop line on the road.\n",
    "\n",
    "-Violation Detection and Processing: If the traffic light is red, the program calls the extract_license_plate and apply_ocr_to_image functions to identify vehicles that cross the white line and to read their license plates. \n",
    "\n",
    "-Displaying Updates: The draw_penalized_text function is invoked to show the penalized license plates in order on the video frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Open the traffic video file\n",
    "    vid = cv2.VideoCapture('traffic_video.mp4')\n",
    "    \n",
    "    # Instantiate the line detector\n",
    "    detector = LineDetector()\n",
    "\n",
    "    # Process each frame in the video\n",
    "    while True:\n",
    "        # Capture the current frame\n",
    "        ret, frame = vid.read()\n",
    "        \n",
    "        # Exit the loop if no frame is returned\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Define the rectangle for traffic light detection\n",
    "        rect = (1700, 40, 100, 250) \n",
    "        \n",
    "        # Determine the color of the traffic light\n",
    "        frame, color = detect_traffic_light_color(frame, rect)\n",
    "        \n",
    "        # Identify the white stop line\n",
    "        frame, mask_line = detector.detect_white_line(frame, color)\n",
    "        \n",
    "        # Check for violations if the light is red\n",
    "        if color == 'red':\n",
    "            # Extract the license plate from the frame\n",
    "            frame, license_plate_images = extract_license_plate(frame, mask_line)\n",
    "            \n",
    "            # Iterate through each detected license plate\n",
    "            for license_plate_image in license_plate_images:\n",
    "                # Use OCR to read the license plate image\n",
    "                text = apply_ocr_to_image(license_plate_image)\n",
    "                \n",
    "                # Validate the detected text format and ensure it hasn't been recorded yet\n",
    "                if text is not None and re.match(\"^[A-Z]{2}\\s[0-9]{3,4}$\", text) and text not in penalized_texts:\n",
    "                    penalized_texts.append(text)\n",
    "                    print(f\"\\nFined license plate: {text}\")\n",
    "\n",
    "                    # Display the license plate image\n",
    "                    plt.figure()\n",
    "                    plt.imshow(license_plate_image, cmap='gray')\n",
    "                    plt.axis('off')\n",
    "                    plt.show()\n",
    "                    \n",
    "\n",
    "        \n",
    "        # Render penalized texts on the frame if any exist\n",
    "        if penalized_texts:\n",
    "            display_penalized_license_plates(frame)\n",
    "\n",
    "        # Show the processed frame\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        # Exit if the ESC key is pressed\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "    # Release the video capture object\n",
    "    vid.release()\n",
    "    \n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin with the main functionalities of our program, there are a few essential setup steps to consider:\n",
    "\n",
    "Haar Cascade Initialization: uses a pre-trained model called haarcascade_russian_plate_number.xml. This model is specifically designed to identify license plates within video frames. \n",
    "\n",
    "List Creation: We also create a list named penalized_texts, which will serve as a storage container for the license plate texts of vehicles that have committed traffic violations. This list is defined globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Load the trained Haar Cascade\n",
    "license_plate_cascade = cv2.CascadeClassifier('haarcascade_russian_plate_number.xml')\n",
    "\n",
    "# Create a list to store unique penalized license plate texts\n",
    "penalized_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Press esc to exit the video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store fined License Plates in MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database and Table Initialization (create_database_and_table):\n",
    "Connects to MySQL using the specified credentials.\n",
    "Creates a new database, sets up a table named license_plates to store records of each license plate along with their associated violation counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_database_and_table()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording Violations:\n",
    "Checks if a particular license plate already exists in the database, if the license plate exists, its violation count is incremented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_database_with_violation(plate_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing All Violations: \n",
    "- Fetches and displays all the recorded license plate violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_all_violations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearing Recorded Data:\n",
    "Deletes all the records in the `license_plates` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clear_license_plates()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
